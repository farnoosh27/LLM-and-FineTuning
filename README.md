Building a GPT from scratch
[Let's build GPT: from scratch, in code, spelled out.](https://www.youtube.com/watch?v=kCc8FmEb1nY)

[Finetuning Large Language Models](https://www.deeplearning.ai/short-courses/finetuning-large-language-models/)

## 3 ways to do fine tuning
According to a [medium article](https://medium.com/p/23473d763b91), there are in general three ways of **fine-tuning** LLMs:
### Self-supervised Learning
### Supervised Learning
### Reinforcement Learning
You can find different fine-tuning tutorial at this [link](https://github.com/ashishpatel26/LLM-Finetuning)
# LLM-and-FineTuning
 One good source for interview questions would be [Master Your ML & DS Interview](https://www.mlstack.cafe/blog/large-language-models-llms-interview-questions)

a useful link, explaining all the topics below can be found at [In-depth guide to fine-tuning LLMs with LoRA and QLoRA](https://www.mercity.ai/blog-post/guide-to-fine-tuning-llms-with-lora-and-qlora#:~:text=QLoRA%20and%20LoRA%20both%20are,of%20a%20standalone%20finetuning%20technique.)

## Transformer documentation on HuggingFace
## Distributed training with ðŸ¤— Accelerate
## Adapter Layers
### Causal LLMâ€™s, Masked LLMâ€™s, and Seq2Seq
[Causal LLMâ€™s, Masked LLMâ€™s, and Seq2Seq](https://medium.com/@tom_21755/understanding-causal-llms-masked-llm-s-and-seq2seq-a-guide-to-language-model-training-d4457bbd07fa)
## PEFT
Check out the [PEFT](https://github.com/huggingface/peft) repo on the GitHub.
## how to leverage RL in finetuning
## TRL
## Reinforcement Learning from Human Feedback (RLHF)
## LORA
the math behind LORA
## LORA + Int 8bit quantization
## QLORA
## Catastrophic forgetting
## what is LAMINI
Lamini is the LLM platform for enterprises and developers to build customized, private models: easier, faster, and higher-performing than any general LLMs.


